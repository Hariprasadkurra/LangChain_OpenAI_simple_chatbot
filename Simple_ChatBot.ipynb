{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SPyLmKojGGwP"},"outputs":[],"source":["!pip install langchain\n","!pip install langchain-community\n","!pip install openai\n","!pip install gradio\n","!pip install huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OJfjEJbwGmbI"},"outputs":[],"source":["import os\n","import gradio as gr\n","from langchain.chat_models import ChatOpenAI\n","from langchain import LLMChain, PromptTemplate\n","from langchain.memory import ConversationBufferMemory"]},{"cell_type":"markdown","metadata":{"id":"VclINVmUGsb1"},"source":["**How to get Open AI API Key?**\n","- Go to https://platform.openai.com/account/api-keys\n","- Create a new Secret Key\n","- Copy the Secret Key for your use."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fci9byLAGrW6"},"outputs":[],"source":["OPENAI_API_KEY=\"OPENAI_API_KEY\"\n","os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r7AnNKzZG2FO"},"outputs":[],"source":["template = \"\"\"You are a helpful assistant to answer user queries.\n","{chat_history}\n","User: {user_message}\n","Chatbot:\"\"\"\n","\n","prompt = PromptTemplate(\n","    input_variables=[\"chat_history\", \"user_message\"], template=template\n",")\n","\n","memory = ConversationBufferMemory(memory_key=\"chat_history\")"]},{"cell_type":"markdown","metadata":{"id":"JhO7eYfNRGU6"},"source":["\n","- Similar to Open AI Mondel we can also use HuggingFace Transformer Models.\n","- Reference links: https://python.langchain.com/docs/integrations/providers/huggingface , https://python.langchain.com/docs/integrations/llms/huggingface_hub.html\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PvYWPZnSQr02"},"outputs":[],"source":["# from langchain.llms import HuggingFacePipeline\n","# hf = HuggingFacePipeline.from_model_id(\n","#     model_id=\"gpt2\",\n","#     task=\"text-generation\",)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IdEV6hMJG4xt"},"outputs":[],"source":["llm_chain = LLMChain(\n","    llm=ChatOpenAI(temperature='0.5', model_name=\"gpt-3.5-turbo\"),\n","    prompt=prompt,\n","    verbose=True,\n","    memory=memory,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wl77cfyIG85T"},"outputs":[],"source":["def get_text_response(user_message,history):\n","    response = llm_chain.predict(user_message = user_message)\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JxyOMt_HAr-"},"outputs":[],"source":["demo = gr.ChatInterface(get_text_response, examples=[\"How are you doing?\",\"What are your interests?\",\"Which places do you like to visit?\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sWVT_2_KHE2G"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    demo.launch() #To create a public link, set `share=True` in `launch()`. To enable errors and logs, set `debug=True` in `launch()`."]}],"metadata":{"colab":{"provenance":[{"file_id":"1hy3hJuM6Y2r0v-8hrB9sc2lCjFmWnYnA","timestamp":1727702491280},{"file_id":"1miK4Xbqv9lYkfe0z6jMh41fA_itulAA0","timestamp":1721973558383}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
